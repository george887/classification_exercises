{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(16, 9))\n",
    "plt.rc('axes.spines', top=False, right=False)\n",
    "plt.rc('patch', ec='black', force_edgecolor=True)\n",
    "plt.rc('font', size=13)\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.In a jupyter notebook, classification_exercises.ipynb, use a python module (pydata or seaborn datasets) containing datasets as a source from the iris data. Create a pandas dataframe, df_iris, from this data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 3 rows\n",
    "df_iris = data(\"iris\")\n",
    "df_iris.head(3)\n",
    "# Another way to load the data set iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns (use attribute shape) \n",
    "df_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "list(df_iris.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "df_iris.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of each column\n",
    "df_iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary statistics for each of the numeric variables. Would you recommend rescaling the data \n",
    "# based on these statistics? I would not rescale. The mean and std are not too far off\n",
    "df_iris.describe() #.describe() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Read the Table1_CustDetails table from the Excel_Exercises.xlsx file into a dataframe named df_excel.\n",
    "\n",
    "assign the first 100 rows to a new dataframe, df_excel_sample\n",
    "print the number of rows of your original dataframe\n",
    "print the first 5 column names\n",
    "print the column names that have a data type of object\n",
    "compute the range for each of the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_excel = pd.read_excel('Spreadsheets_Exercises.xlsx', sheet_name='Table1_CustDetails')\n",
    "df_excel = pd.read_csv(\"Spreadsheets_Exercises.csv\")\n",
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the first 100 rows to a new dataframe, df_excel_sample\n",
    "df_excel_sample = df_excel.head(100)\n",
    "df_excel_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the number of rows of your original dataframe\n",
    "df_excel.shape\n",
    "# df_excel.index too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 5 column names\n",
    "df_excel.columns[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names that have a data type of object\n",
    "df_excel.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a list comprehension to get column names of oject type\n",
    "[col for col in df_excel if df_excel[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using a for loop to get column names of oject type\n",
    "for col in df_excel:\n",
    "    if df_excel[col].dtype == \"object\":\n",
    "        print(col)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the range for each of the numeric variables\n",
    "# select dtypes of numbers with a np array. Then get the range\n",
    "numeric_vars = df_excel.select_dtypes(np.number)\n",
    "numeric_range = numeric_vars.max() - numeric_vars.min()\n",
    "numeric_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Read the data from this google sheet into a dataframe, df_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the first 3 rows\n",
    "\n",
    "sheet_url = 'https://docs.google.com/spreadsheets/d/1Uhtml8KY19LILuZsrDtlsHHDC9wuDGUSe8LTEwvdI5g/edit#gid=341089357'    \n",
    "\n",
    "csv_export_url = sheet_url.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "\n",
    "df_googlesheet = pd.read_csv(csv_export_url)\n",
    "df_googlesheet.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of rows and columns\n",
    "df_googlesheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names. .columns attribute\n",
    "df_googlesheet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the columns to a list\n",
    "df_googlesheet.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the data type of each column\n",
    "df_googlesheet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the summary statistics for each of the numeric variables .T transposes\n",
    "df_googlesheet.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_googlesheet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unique values for each of your categorical variables. the .dtypes attribute\n",
    "for col in df_googlesheet:\n",
    "    if df_googlesheet[col].dtypes == 'object':\n",
    "        print(f'{col} has {df_googlesheet[col].nunique()} unique values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a new python module, acquire.py to hold the following data aquisition functions:\n",
    "\n",
    "### Make a function named get_titanic_data that returns the titanic data from the codeup data science database as a pandas data frame. Obtain your data from the Codeup Data Science Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import credentials from env. Also import os\n",
    "from env import host, user, password\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish mysql connection\n",
    "def get_connection(db, user=user, host=host, password=password):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable for sql query\n",
    "def new_titanic_data():\n",
    "    sql_query = 'SELECT * FROM passengers'\n",
    "    df = pd.read_sql(sql_query, get_connection('titanic_db'))\n",
    "    df.to_csv('titanic_df.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_titanic_data(cached=False):\n",
    "    '''\n",
    "    This function reads in titanic data from Codeup database if cached == False\n",
    "    or if cached == True reads in titanic df from a csv file, returns df\n",
    "    '''\n",
    "    if cached or os.path.isfile('titanic_df.csv') == False:\n",
    "        df = new_titanic_data()\n",
    "    else:\n",
    "        df = pd.read_csv('titanic_df.csv', index_col=0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = get_titanic_data(cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function named get_iris_data that returns the data from the iris_db on the codeup data science database as a pandas DataFrame. The returned DataFrame should include the actual name of the species in addition to the species_ids. Obtain your data from the Codeup Data Science Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_iris_data():\n",
    "    '''\n",
    "    This function reads the iris data from the Codeup db into a df,\n",
    "    writes it to a csv file, and returns the df.\n",
    "    '''\n",
    "    sql_query = \"\"\"\n",
    "                SELECT species_id,\n",
    "                measurement_id\n",
    "                species_name,\n",
    "                sepal_length,\n",
    "                sepal_width,\n",
    "                petal_length,\n",
    "                petal_width\n",
    "                FROM measurements\n",
    "                JOIN species\n",
    "                USING(species_id)\n",
    "                \"\"\"\n",
    "    df = pd.read_sql(sql_query, get_connection('iris_db'))\n",
    "    df.to_csv('iris_df.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_data(cached=False):\n",
    "    '''\n",
    "    This function reads in iris data from Codeup database if cached == False\n",
    "    or if cached == True reads in iris df from a csv file, returns df\n",
    "    '''\n",
    "    if cached or os.path.isfile('iris_df.csv') == False:\n",
    "        df = new_iris_data()\n",
    "    else:\n",
    "        df = pd.read_csv('iris_df.csv', index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = get_iris_data(cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation Exercise\n",
    "### The end product of this exercise should be the specified functions in a python script named prepare.py. Do these in your classification_exercises.ipynb first, then transfer to the prepare.py file.\n",
    "\n",
    "This work should all be saved in your local classification-exercises repo. Then add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data\n",
    "\n",
    " - Use the function defined in acquire.py to load the iris data.\n",
    " - Drop the species_id and measurement_id columns.\n",
    " - Rename the species_name column to just species.\n",
    " - Create dummy variables of the species name.\n",
    " - Create a function named prep_iris that accepts the untransformed iris data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing acquire file created\n",
    "import acquire\n",
    "from acquire import get_iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Use the function defined in acquire.py to load the iris data. \n",
    "# Creating irisdf using the cached file created\n",
    "irisdf = get_iris_data()\n",
    "irisdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Drop the species_id and measurement_id columns.\n",
    "cols_to_drop = ['species_id','measurement_id']\n",
    "irisdf = irisdf.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irisdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Rename the species_name column to just species.\n",
    "irisdf = irisdf.rename({'species_name':'species'}, axis = 1)\n",
    "irisdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Create dummy variables of the species name.\n",
    "dummy_df = pd.get_dummies(irisdf[['species']], dummy_na=False)\n",
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now going to concat the irisdf and dummy_df\n",
    "irisdf = pd.concat([irisdf, dummy_df], axis = 1)\n",
    "irisdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function named prep_iris that accepts the untransformed iris data, and returns\n",
    "# the data with the transformations above applied.\n",
    "def prep_iris(irisdf):\n",
    "    '''\n",
    "    This function acquires and prepares the iris data from a local csv, default.\n",
    "    Passing cached=False acquires fresh data from Codeup db and writes to csv.\n",
    "    Returns the iris df with dummy variables encoding species.\n",
    "    '''\n",
    "    # use my aquire function to read data into a df from a csv file\n",
    "    irisdf = get_iris_data(cached)\n",
    "    cols_to_drop = ['species_id','measurement_id']\n",
    "    irisdf = irisdf.drop(columns=cols_to_drop)\n",
    "    irisdf = irisdf.rename({'species_name':'species'}, axis = 1)\n",
    "    dummy_df = pd.get_dummies(irisdf[['species']], dummy_na=False)\n",
    "    irisdf = pd.concat([irisdf, dummy_df], axis = 1)\n",
    "    return irisdf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Data\n",
    "\n",
    "## Use the function you defined in acquire.py to load the titanic data set.\n",
    "- A. Handle the missing values in the embark_town and embarked columns.\n",
    "- B. Remove the deck column.\n",
    "- C. Create a dummy variable of the embarked column.\n",
    "- D. Scale the age and fare columns using a min max scaler. Why might this be beneficial? When might you not want to do this?\n",
    "- E. Fill the missing values in age. The way you fill these values is up to you. Consider the tradeoffs of different methods.\n",
    "- F. Create a function named prep_titanic that accepts the untransformed titanic data, and returns the data with the transformations above applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the acquire file and importing the function\n",
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a df from the acquire file\n",
    "titanic_df = get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  891 non-null    int64  \n",
      " 1   survived      891 non-null    int64  \n",
      " 2   pclass        891 non-null    int64  \n",
      " 3   sex           891 non-null    object \n",
      " 4   age           714 non-null    float64\n",
      " 5   sibsp         891 non-null    int64  \n",
      " 6   parch         891 non-null    int64  \n",
      " 7   fare          891 non-null    float64\n",
      " 8   embarked      889 non-null    object \n",
      " 9   class         891 non-null    object \n",
      " 10  deck          203 non-null    object \n",
      " 11  embark_town   889 non-null    object \n",
      " 12  alone         891 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 97.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "passenger_id      0\n",
       "survived          0\n",
       "pclass            0\n",
       "sex               0\n",
       "age             177\n",
       "sibsp             0\n",
       "parch             0\n",
       "fare              0\n",
       "embarked          2\n",
       "class             0\n",
       "deck            688\n",
       "embark_town       2\n",
       "alone             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. Handle the missing values in the embark_town and embarked columns. Shows 889 values\n",
    "# for both embark_town and embarked column. Should be 891 so missing 2\n",
    "titanic_df.info()\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_id      0\n",
       "survived          0\n",
       "pclass            0\n",
       "sex               0\n",
       "age             177\n",
       "sibsp             0\n",
       "parch             0\n",
       "fare              0\n",
       "embarked          0\n",
       "class             0\n",
       "deck            688\n",
       "embark_town       0\n",
       "alone             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. Handle the missing values in the embark_town and embarked columns.\n",
    "# the ~ with the isnull() method will remove the null values\n",
    "titanic_df = titanic_df[~titanic_df.embark_town.isnull()]\n",
    "titanic_df = titanic_df[~titanic_df.embarked.isnull()]\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  \n",
       "0        S  Third  Southampton      0  \n",
       "1        C  First    Cherbourg      0  \n",
       "2        S  Third  Southampton      1  \n",
       "3        S  First  Southampton      0  \n",
       "4        S  Third  Southampton      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B. Remove the deck column.\n",
    "cols_to_drop = ['deck']\n",
    "titanic_df = titanic_df.drop(columns=cols_to_drop)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  embark_town  alone  embarked_C  embarked_Q  embarked_S  \n",
       "0        S  Third  Southampton      0           0           0           1  \n",
       "1        C  First    Cherbourg      0           1           0           0  \n",
       "2        S  Third  Southampton      1           0           0           1  \n",
       "3        S  First  Southampton      0           0           0           1  \n",
       "4        S  Third  Southampton      1           0           0           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C. Create a dummy variable of the embarked column.\n",
    "df_dummy = pd.get_dummies(titanic_df[['embarked']], dummy_na=False)\n",
    "df_dummy.head()\n",
    "# Now we want to concat the dummy df to the original df.\n",
    "titanic_df = pd.concat([titanic_df, df_dummy], axis = 1)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You first want to train, validate, test and split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def titanic_split(df):\n",
    "    '''\n",
    "    This function performs split on titanic data, stratify survived.\n",
    "    Returns train, validate, and test dfs.\n",
    "    '''\n",
    "    train_validate, test = train_test_split(titanic_df, test_size=.2, \n",
    "                                        random_state=123, \n",
    "                                        stratify=titanic_df.survived)\n",
    "\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, \n",
    "                                   random_state=123, \n",
    "                                   stratify=train_validate.survived)\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train -> (497, 15)\n",
      "validate -> (214, 15)\n",
      "test -> (178, 15)\n"
     ]
    }
   ],
   "source": [
    "# Now you can see the shaped of each train, validate, and split\n",
    "print(f'train -> {train.shape}')\n",
    "print(f'validate -> {validate.shape}')\n",
    "print(f'test -> {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch      fare  \\\n",
       "583           583         0       1    male  36.0      0      0   40.1250   \n",
       "337           337         1       1  female  41.0      0      0  134.5000   \n",
       "50             50         0       3    male   7.0      4      1   39.6875   \n",
       "218           218         1       1  female  32.0      0      0   76.2917   \n",
       "31             31         1       1  female   NaN      1      0  146.5208   \n",
       "\n",
       "    embarked  class  embark_town  alone  embarked_C  embarked_Q  embarked_S  \n",
       "583        C  First    Cherbourg      1           1           0           0  \n",
       "337        C  First    Cherbourg      1           1           0           0  \n",
       "50         S  Third  Southampton      0           0           0           1  \n",
       "218        C  First    Cherbourg      1           1           0           0  \n",
       "31         C  First    Cherbourg      0           1           0           0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing skylearn minmaxscaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Scale the age and fare columns using a min max scaler. Why might this be beneficial?\n",
    "# When might you not want to do this?\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(titanic_df[[\"age\"]])\n",
    "titanic_df.age = scaler.transform(titanic_df[[\"age\"]])\n",
    "\n",
    "scaler.fit(titanic_df[[\"fare\"]])\n",
    "titanic_df.fare = scaler.transform(titanic_df[[\"fare\"]])\n",
    "\n",
    "titanic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E. Fill the missing values in age. The way you fill these values is up to you. \n",
    "# Consider the tradeoffs of different methods.\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "\n",
    "train[\"age\"] = imputer.fit_transform(train[['age']])\n",
    "\n",
    "# Checking to see if the nulls were taken care of. Yep\n",
    "train['age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the validate and test df age columns\n",
    "\n",
    "validate['age'] = imputer.transform(validate[['age']])\n",
    "test['age'] = imputer.transform(test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for imputing. Putting everything done for imputing here\n",
    "def impute_age(train, validate, test):\n",
    "    '''\n",
    "    This function imputes the mean of the age column into\n",
    "    observations with missing values.\n",
    "    Returns transformed train, validate, and test df.\n",
    "    '''\n",
    "    # create the imputer object with mean strategy\n",
    "    imputer = SimpleImputer(strategy = 'mean')\n",
    "    \n",
    "    # fit on and transform age column in train\n",
    "    train['age'] = imputer.fit_transform(train[['age']])\n",
    "    \n",
    "    # transform age column in validate\n",
    "    validate['age'] = imputer.transform(validate[['age']])\n",
    "    \n",
    "    # transform age column in test\n",
    "    test['age'] = imputer.transform(test[['age']])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F. Create a function named prep_titanic that accepts the untransformed titanic data, \n",
    "# and returns the data with the transformations above applied.\n",
    "\n",
    "def prep_titanic(titanic_df):\n",
    "    '''\n",
    "    This function reads titanic data into a df from a csv file.\n",
    "    Returns prepped train, validate, and test dfs\n",
    "    '''\n",
    "    # use my acquire function to read data into a df from a csv file\n",
    "    df = get_titanic_data(cached)\n",
    "    \n",
    "    # drop rows where embarked/embark town are null values\n",
    "    df = df[~df.embarked.isnull()]\n",
    "    \n",
    "    # encode embarked using dummy columns\n",
    "    titanic_dummies = pd.get_dummies(df.embarked, drop_first=True)\n",
    "    \n",
    "    # join dummy columns back to df\n",
    "    df = pd.concat([df, titanic_dummies], axis=1)\n",
    "    \n",
    "    # drop the deck column\n",
    "    df = df.drop(columns='deck')\n",
    "    \n",
    "    # split data into train, validate, test dfs\n",
    "    train, validate, test = titanic_split(df)\n",
    "    \n",
    "    # impute mean of age into null values in age column\n",
    "    train, validate, test = impute_age(train, validate, test)\n",
    "    \n",
    "    return train, validate, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
